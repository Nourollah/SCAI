trainer: equiformerv2_forces


dataset:
  train:
    format: ase_read_multi
    src: databases/train
    pattern: '*.traj'
    a2g_args:
      r_energy: true
      r_forces: true
    use_tqdm: true
    keep_in_memory: True
    key_mapping:
      atoms: "atomic_numbers"
  val:
    format: ase_read_multi
    src: databases/val
    pattern: '*.traj'
    a2g_args:
      r_energy: true
      r_forces: true
    use_tqdm: true
    keep_in_memory: True
    key_mapping:
      atoms: "atomic_numbers"
  test:
    format: ase_read_multi
    src: databases/test
    pattern: '*.traj'
    a2g_args:
      r_energy: true
      r_forces: true
    use_tqdm: true
    keep_in_memory: True
    key_mapping:
      atoms: "atomic_numbers"

logger: wandb

outputs:
  energy:
    property: energy
    shape: 1
    level: system
  forces:
    property: forces
    irrep_dim: 1
    level: atom
    train_on_free_atoms: True
    eval_on_free_atoms: True

loss_functions:
  - energy:
      fn: mae
      coefficient: 4
  - forces:
      fn: l2mae
      coefficient: 100

evaluation_metrics:
  metrics:
    energy:
      - mae
    forces:
      - mae
      - cosine_similarity
      - magnitude_error
    misc:
      - energy_forces_within_threshold
  primary_metric: forces_mae

hide_eval_progressbar: False


model:
  name: escn
  num_layers: 20
  max_neighbors: 20
  cutoff: 12.0
  sphere_channels: 160
  hidden_channels: 384
  lmax_list: [6]
  mmax_list: [3]
  num_sphere_samples: 128
  distance_function: "gaussian"
  regress_forces: True
  use_pbc: False
  basis_width_scalar: 2.0
  otf_graph: True

optim:
  batch_size: 8
  eval_batch_size: 8
  num_workers: 8
  lr_initial: 0.0008
  optimizer: AdamW
  optimizer_params: {"amsgrad": True}
  eval_every: 1
  lr_gamma: 0.3
  lr_milestones: # epochs at which lr_initial <- lr_initial * lr_gamma
    - 433166
    - 541460
    - 649750
  warmup_steps: 100
  warmup_factor: 0.2
  max_epochs: 100
  force_coefficient: 100
  energy_coefficient: 4
  clip_grad_norm: 20
  ema_decay: 0.999
